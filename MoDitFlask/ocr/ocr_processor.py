# ocr/ocr_processor.py
from google.cloud import vision
import io, cv2
from pathlib import Path
import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/home/ubuntu/modit_docu/regal-dynamo-459905-a6-33e9e8214e12.json"


def preprocess_image(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    enhanced = cv2.equalizeHist(gray)
    temp_path = Path(image_path).with_name("preprocessed.jpg")
    cv2.imwrite(str(temp_path), enhanced)
    return str(temp_path)

def run_ocr(image_path):
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    preprocessed_path = preprocess_image(image_path)

    # Vision API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = vision.ImageAnnotatorClient()

    with io.open(preprocessed_path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)

    # ë¬¸ì„œ í˜•íƒœë¡œ OCR ì‹¤í–‰ (ë‹¨ì–´, ë¬¸ë‹¨ êµ¬ë¶„ë¨)
    response = client.document_text_detection(
        image=image,
        image_context={"language_hints": ["ko"]}  # í•œêµ­ì–´ ì¸ì‹ ìµœì í™”
    )

    # ì—ëŸ¬ í™•ì¸
    if response.error.message:
        raise Exception(f'OCR API Error: {response.error.message}')

    # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    texts = response.full_text_annotation.text
    print("ğŸ“„ ì¸ì‹ ê²°ê³¼:\n", texts)
    return texts
